{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: 2D WTMM and automated terminus picking\n",
    "\n",
    "_Last modified 2022-07-01._\n",
    "\n",
    "This script analyzes image subsets over the glaciers using the adapted 2D Wavelet Transform Modulus Maxima (WTMM) segmentation method, producing terminus delineations.\n",
    "\n",
    "The code is streamlined to analyze images for hundreds of glaciers, specifically, the marine-terminating glaciers along the periphery of Greenland. For use on other glaciers, sections of code must be modified:\n",
    "\n",
    "    ##########################################################################################\n",
    "    \n",
    "    code to modify\n",
    "\n",
    "    ##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyfftw\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import os\n",
    "import json\n",
    "import geojson\n",
    "import pandas as pd\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import datetime\n",
    "from pyproj import Proj\n",
    "\n",
    "from Xsmurf_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jukes/anaconda3/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "/home/jukes/anaconda3/lib/python3.7/site-packages/pyproj/crs/crs.py:294: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  projstring = _prepare_from_string(\" \".join((projstring, projkwargs)))\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "basepath = '/media/jukes/jukes1/LS8aws/' # contains glacier BoxID folders with downloaded/preprocessed images\n",
    "csvpath = '/home/jukes/Documents/Sample_glaciers/' # path to where CSV files are saved\n",
    "rotated_foldername = 'rotated_c2/' # name of subfolder containing preprocessed images for each glacier\n",
    "PSproj = Proj(init='EPSG:3413') # desired projection for output delineations\n",
    "\n",
    "# set glacier IDs here\n",
    "BoxIDs = ['001', '002', '003', '004', '005', '006', '007', '008', '009', \\\n",
    "          '010', '011', '012', '013', '014', '015', '016', '017', '018', \\\n",
    "          '019', '020', '021', '022', '023', '024', '025', '026', '027', \\\n",
    "          '028', '029', '030', '031', '032', '033', '034', '035', '036', \\\n",
    "          '037', '038', '039', '040', '041', '042', '043', '044', '045', \\\n",
    "          '046', '047', '048', '049', '050']\n",
    "# BoxIDs = list(pd.read_csv(csvpath+'Buffdist_SE_1.csv',dtype=str).BoxID) # read from a CSV file\n",
    "print(BoxIDs)\n",
    "\n",
    "# Default values are shown for the following parameters:\n",
    "# Wavelet parameters (dictates number of spatial scales analyzed):\n",
    "amin = 1\n",
    "nOct = 5\n",
    "nVox = 10\n",
    "wavelet = 'gauss'\n",
    "\n",
    "# Terminus pick parameters:\n",
    "size_thresh = 0.4 # minimum size percentile across all images (0.4 recommended)\n",
    "mod_thresh = 0.7 # minimum linemeanmod percentile across all images (0.7 recommended)\n",
    "arg_thresh = 0.1 # minimum left-right argument fraction (0.1 recommended)\n",
    "metric = 0 # 0 = mass, 1 = scaledmass, 2 = size, DEFAULT = 1\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How would you like to run the analysis?\n",
    "\n",
    "    1) All images in a loop (slow)\n",
    "    2) In batches (fast)\n",
    "    3) Just one image (slowest, for development purposes only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1) Process all images in series (loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box raster dimensions: (235, 221)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 302 R_LC08_L1TP_033005_20170414_20200904_02_T1_B8_Buffer001_PS.pgm\n",
      "Scale: 6.976744186046512\n",
      "Dimemsions do not match: (235, 235) (292, 292)\n",
      "Dimemsions do not match: (235, 235) (292, 292)\n",
      "Dimemsions do not match: (235, 235) (292, 292)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-123d6ddd11c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m# chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mcmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwtmmchains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasked_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automated-glacier-terminus/Xsmurf_functions.py\u001b[0m in \u001b[0;36mwtmmchains\u001b[0;34m(mm, a, keepClosed, scale, counter)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scale number:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;31m# grab original shape of mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m     \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Process all the images for the glaciers specified and show top 5 terminus chains\n",
    "for BoxID in BoxIDs:\n",
    "    t0 = time.time()\n",
    "    processed_image_path = basepath+'Box'+BoxID+'/'+rotated_foldername\n",
    "    imagelist = []\n",
    "    for file in os.listdir(processed_image_path):\n",
    "        if file.endswith('PS.pgm') and 'L1TP' in file: # grab the L1TP corrected images only\n",
    "            imagelist.append(file)\n",
    "        elif file.endswith('cut.pgm'):\n",
    "            boxfile = file\n",
    "        \n",
    "    # Load terminus box\n",
    "    box = Image.open(processed_image_path+boxfile)\n",
    "    box_array = np.array(box)\n",
    "    if len(box_array.shape) == 3: # 3D array\n",
    "        box_array = box_array[:,:,0]/255 # grab 1D slice from array and convert to binary\n",
    "    elif len(box_array.shape) == 2: # 2D array\n",
    "        box_array = box_array # already in binary\n",
    "    print('Box raster dimensions:', box_array.shape)\n",
    "    plt.imshow(box_array); plt.show()  # Display mask\n",
    "\n",
    "    # read in image Greenland Polar Stereographic coordinates\n",
    "    PSy = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_yidx_Box'+BoxID+'.csv',\n",
    "                              delimiter=' ',header=None))\n",
    "    # read in Greenland Polar Stereographic coordinates\n",
    "    PSx = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_xidx_Box'+BoxID+'.csv',\n",
    "                              delimiter=' ',header=None))\n",
    "    \n",
    "    # hold all top chains produced from terminus picking\n",
    "    topchains_alldfs = []\n",
    "    \n",
    "    image_num = 1\n",
    "    # process all the images\n",
    "    for image in imagelist:\n",
    "        img = Image.open(processed_image_path+image)\n",
    "        print(str(image_num)+' out of '+str(len(imagelist))+' '+image)\n",
    "        \n",
    "        # WTMM\n",
    "        counter = 0\n",
    "        all_cmm = [] # to hold all the chains produced\n",
    "        # ascend over all scales\n",
    "        for iOct in np.arange(0, nOct):\n",
    "            for iVox in np.arange(0, nVox):\n",
    "\n",
    "                # calculate scale in pixels\n",
    "                scale = 6/0.86*amin*2**(iOct+(iVox/nVox))\n",
    "                print('Scale: '+str(scale))\n",
    "\n",
    "                # wavelet transform\n",
    "                [dx, dy, mm, m, a] = wtmm2d_v(img, wavelet, scale)\n",
    "                \n",
    "                # emask\n",
    "                masked_a = emask(box_array, a)\n",
    "                masked_mm = emask(box_array, mm)\n",
    "                masked_m = emask(box_array, m)\n",
    "\n",
    "                # chain\n",
    "                cmm = wtmmchains(masked_mm,masked_a,0,scale,counter)\n",
    "\n",
    "                # increment\n",
    "                all_cmm.extend(cmm)\n",
    "                counter = counter +1 \n",
    "       \n",
    "    \n",
    "        # Make directory to store chain jsons:\n",
    "        imgfolder = processed_image_path+image+'_chains/'\n",
    "        if not os.path.exists(imgfolder):\n",
    "            os.mkdir(imgfolder)\n",
    "\n",
    "        # Pick the terminus line\n",
    "        # Find maximum mods and sizes for thresholding\n",
    "        mods = []; sizes = []\n",
    "        for chain in all_cmm:\n",
    "            sizes.append(chain.size)\n",
    "            mods.append(chain.linemeanmod)\n",
    "        maxmod = np.nanmax(mods); maxsize = np.nanmax(sizes)\n",
    "            \n",
    "        mass_or_size = []\n",
    "        passed_chains = []\n",
    "        passcount = 0\n",
    "        for chain in all_cmm:\n",
    "            if chain.linemeanmod > mod_thresh*maxmod: # only chains that pass the mod threshold\n",
    "#                 if chain.size > size_thresh*maxsize: # only chains that pass the size threshold\n",
    "                if chain.size > size_thresh*np.sqrt(len(box_array[box_array > 0])):\n",
    "                    [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "                    if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "                        if metric == 0:\n",
    "                            mass_or_size.append(chain.mass)\n",
    "                        elif metric == 1:\n",
    "                            mass_or_size.append(chain.scaledmass)\n",
    "                        else:\n",
    "                            mass_or_size.append(chain.size)\n",
    "                        passcount += 1\n",
    "                        passed_chains.append(chain)\n",
    "        \n",
    "        if passcount > 0: # if chains remain:\n",
    "            # sort by mass or size and grab the top 5\n",
    "            zipped = zip(mass_or_size, passed_chains)              \n",
    "            top_chains = sorted(zipped,reverse=True,\n",
    "                                key=lambda zipped: zipped[0])[:5] # sort chains that passed\n",
    "\n",
    "            # grab info from top 5 chains\n",
    "            scales = []; boxids = []; orders = []; scenes = []; dates = []\n",
    "            # write the top 5 to json\n",
    "            for chain in top_chains:\n",
    "                # grab the chain\n",
    "                chain = chain[1]\n",
    "\n",
    "                # convert dtypes to json serializable dtypes:\n",
    "                chain.size = int(chain.size)\n",
    "                chain.linemeanmod = float(chain.linemeanmod)\n",
    "                chain.mass = float(chain.mass)\n",
    "                chain.scaledmass = float(chain.scaledmass)\n",
    "                chain.args = list(map(float, chain.args))\n",
    "                chain.ix = list(map(int, chain.ix))\n",
    "                chain.iy = list(map(int, chain.iy))\n",
    "                chain.scale = str(chain.scale)\n",
    "                scales.append(chain.scale.zfill(3))\n",
    "                \n",
    "                # grab geographic coordinates\n",
    "                PSys = PSy[chain.iy, chain.ix]; PSxs = PSx[chain.iy,chain.ix]\n",
    "                lons, lats = PSproj(PSxs, PSys, inverse=True) # project to WGS84\n",
    "                polyline = geojson.LineString(list(zip(lons, lats))) # create polyline\n",
    "                features = []\n",
    "                date = datetime.datetime.strptime(image[19:27], '%Y%m%d'); date = date.strftime(\"%Y-%m-%d\")\n",
    "                features.append(geojson.Feature(geometry=polyline,\n",
    "                                                properties={'datetime':date}))\n",
    "                feature_collection = geojson.FeatureCollection(features)\n",
    "\n",
    "                # write chain object to json file\n",
    "                with open(imgfolder+chain.scale.zfill(3)+'_chain.json', 'w') as f:\n",
    "                    json.dump(chain.__dict__, f)\n",
    "                # write georeferenced chain to geojson file\n",
    "                with open(imgfolder+chain.scale.zfill(3)+'_chain.geojson', 'w') as f:\n",
    "                    geojson.dump(feature_collection, f)\n",
    "\n",
    "            topchains_df = pd.DataFrame(top_chains,columns=['Metric','chain'])\n",
    "            rows = len(topchains_df)\n",
    "\n",
    "            for n in range(0,rows):\n",
    "                boxids.append(BoxID.zfill(3)) # box string\n",
    "                order = n+1 # order of chains (already sorted)\n",
    "                orders.append(order)\n",
    "                scenes.append(image[2:-20])\n",
    "                date = datetime.datetime.strptime(image[19:27], '%Y%m%d')\n",
    "                date = date.strftime(\"%Y-%m-%d\"); dates.append(date)\n",
    "            topchains_df['BoxID'] = boxids; topchains_df['Scene'] = scenes\n",
    "            topchains_df['datetimes'] = dates;\n",
    "            topchains_df['Scale'] = scales; topchains_df['Order'] = orders\n",
    "            topchains_df = topchains_df[['BoxID','Scene','datetimes','Scale','Metric','Order']]\n",
    "            topchains_alldfs.append(topchains_df)\n",
    "\n",
    "            # visualize top chains:\n",
    "            colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(np.array(img), aspect='equal', cmap = 'gray')\n",
    "            plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "            for k in range(0, len(top_chains)): # plot chains (purple = top, yellow = 5th)\n",
    "                plt.plot(top_chains[len(top_chains)-1-k][1].ix, \n",
    "                         top_chains[len(top_chains)-1-k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "            plt.title(date, fontsize=16)\n",
    "            plt.xticks([]); plt.yticks([])\n",
    "            # make directory to save results to:\n",
    "            resultsfolder = processed_image_path+'results/'\n",
    "            if not os.path.exists(resultsfolder):\n",
    "                os.mkdir(resultsfolder)\n",
    "            plt.savefig(resultsfolder+date+'_'+image[:-4]+'_topchains.png',dpi=200)\n",
    "            plt.show()\n",
    "\n",
    "        image_num = image_num +1\n",
    "\n",
    "    print(str(time.time() - t0)+' sec to process '+str(len(imagelist))+' images.')\n",
    "    # write terminus pick file\n",
    "    today = datetime.datetime.now().strftime(\"%Y_%m_%d\")  # today's date string\n",
    "    terminuspick_df = pd.concat(topchains_alldfs) # concatenate all the top pick data together\n",
    "    terminuspick_df.to_csv(csvpath+'terminuspicks_Box'+BoxID.zfill(3)+'_'+today+'.csv') # write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "[dx, dy, mm, m, a] = wtmm2d_v(img, wavelet, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 276)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2) Parallel process images in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run wtmm2d_img() in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Batch size: 10\n"
     ]
    }
   ],
   "source": [
    "# check number of cpus on machine using os:\n",
    "print(os.cpu_count())\n",
    "\n",
    "################################################################################################\n",
    "# set batch size accordingly\n",
    "# recommendation is to leave one or two cpus available for other background processing\n",
    "batch_size = 10\n",
    "print('Batch size:',batch_size)\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtmm2d_img(image):\n",
    "    topchains_dfs = []       \n",
    "    img = Image.open(processed_image_path+image)\n",
    "    print(image)\n",
    "       \n",
    "    # Make directory to store chain jsons:\n",
    "    imgfolder = processed_image_path+image+'_chains/'\n",
    "    if not os.path.exists(imgfolder):\n",
    "        os.mkdir(imgfolder)\n",
    "        \n",
    "    # WTMM\n",
    "    counter = 0\n",
    "    all_cmm = [] # to hold all the chains produced\n",
    "    # ascend over all scales\n",
    "    for iOct in np.arange(0, nOct):\n",
    "        for iVox in np.arange(0, nVox):\n",
    "\n",
    "            # calculate scale in pixels\n",
    "            scale = 6/0.86*amin*2**(iOct+(iVox/nVox))\n",
    "\n",
    "            # wavelet transform\n",
    "            [dx, dy, mm, m, a] = wtmm2d_v2(img, wavelet, scale)\n",
    "\n",
    "            # emask\n",
    "            masked_a = emask(box_array, a)\n",
    "            masked_mm = emask(box_array, mm)\n",
    "            masked_m = emask(box_array, m)\n",
    "\n",
    "            # chain\n",
    "            cmm = wtmmchains(masked_mm,masked_a,0,scale,counter)\n",
    "\n",
    "            # increment\n",
    "            all_cmm.extend(cmm)\n",
    "            counter = counter +1 \n",
    "\n",
    "    # Pick the terminus line\n",
    "    # Find maximum mods and sizes for thresholding\n",
    "    mods = []; sizes = []\n",
    "    for chain in all_cmm:\n",
    "        sizes.append(chain.size)\n",
    "        mods.append(chain.linemeanmod)\n",
    "    maxmod = np.nanmax(mods); maxsize = np.nanmax(sizes)\n",
    "\n",
    "    mass_or_size = []; passed_chains = []; passcount = 0\n",
    "    for chain in all_cmm:\n",
    "        if chain.linemeanmod > mod_thresh*maxmod: # only chains that pass the mod threshold\n",
    "#                 if chain.size > size_thresh*maxsize: # only chains that pass the size threshold\n",
    "            if chain.size > size_thresh*np.sqrt(len(box_array[box_array > 0])):\n",
    "                [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "                if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "                    if metric == 0:\n",
    "                        mass_or_size.append(chain.mass)\n",
    "                    elif metric == 1:\n",
    "                        mass_or_size.append(chain.scaledmass)\n",
    "                    else:\n",
    "                        mass_or_size.append(chain.size)\n",
    "                    passcount += 1\n",
    "                    passed_chains.append(chain)\n",
    "\n",
    "    if passcount > 0: # if chains remain:\n",
    "        # sort by mass or size and grab the top 5\n",
    "        zipped = zip(mass_or_size, passed_chains)              \n",
    "        top_chains = sorted(zipped,reverse=True,\n",
    "                            key=lambda zipped: zipped[0])[:5] # sort chains that passed\n",
    "\n",
    "        # grab info from top 5 chains\n",
    "        scales = []; boxids = []; orders = []; scenes = []; dates = []\n",
    "        # write the top 5 to json\n",
    "        for chain in top_chains:\n",
    "            # grab the chain\n",
    "            chain = chain[1]\n",
    "\n",
    "            # convert dtypes to json serializable dtypes:\n",
    "            chain.size = int(chain.size)\n",
    "            chain.linemeanmod = float(chain.linemeanmod)\n",
    "            chain.mass = float(chain.mass)\n",
    "            chain.scaledmass = float(chain.scaledmass)\n",
    "            chain.args = list(map(float, chain.args))\n",
    "            chain.ix = list(map(int, chain.ix))\n",
    "            chain.iy = list(map(int, chain.iy))\n",
    "            chain.scale = str(chain.scale)\n",
    "            scales.append(chain.scale.zfill(3))\n",
    "\n",
    "            # grab geographic coordinates\n",
    "            PSys = PSy[chain.iy, chain.ix]; PSxs = PSx[chain.iy,chain.ix]\n",
    "            lons, lats = PSproj(PSxs, PSys, inverse=True) # project to WGS84\n",
    "            polyline = geojson.LineString(list(zip(lons, lats))) # create polyline\n",
    "            features = []\n",
    "            date = datetime.datetime.strptime(image[19:27], '%Y%m%d'); date = date.strftime(\"%Y-%m-%d\")\n",
    "            features.append(geojson.Feature(geometry=polyline,\n",
    "                                            properties={'datetime':date}))\n",
    "            feature_collection = geojson.FeatureCollection(features)\n",
    "\n",
    "            # write chain object to json file\n",
    "            with open(imgfolder+chain.scale.zfill(3)+'_chain.json', 'w') as f:\n",
    "                json.dump(chain.__dict__, f)\n",
    "            # write georeferenced chain to geojson file\n",
    "            with open(imgfolder+chain.scale.zfill(3)+'_chain.geojson', 'w') as f:\n",
    "                geojson.dump(feature_collection, f)\n",
    "\n",
    "        topchains_df = pd.DataFrame(top_chains,columns=['Metric','chain'])\n",
    "        rows = len(topchains_df)\n",
    "\n",
    "        for n in range(0,rows):\n",
    "            boxids.append(BoxID.zfill(3)) # box string\n",
    "            order = n+1 # order of chains (already sorted)\n",
    "            orders.append(order)\n",
    "            scenes.append(image[2:-20])\n",
    "            date = datetime.datetime.strptime(image[19:27], '%Y%m%d')\n",
    "            date = date.strftime(\"%Y-%m-%d\"); dates.append(date)\n",
    "        topchains_df['BoxID'] = boxids; topchains_df['Scene'] = scenes\n",
    "        topchains_df['datetimes'] = dates;\n",
    "        topchains_df['Scale'] = scales; topchains_df['Order'] = orders\n",
    "        topchains_df = topchains_df[['BoxID','Scene','datetimes','Scale','Metric','Order']]\n",
    "        topchains_dfs.append(topchains_df)\n",
    "\n",
    "        # visualize top chains:\n",
    "        colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(np.array(img), aspect='equal', cmap = 'gray')\n",
    "        plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "        for k in range(0, len(top_chains)): # plot chains (purple = top, yellow = 5th)\n",
    "            plt.plot(top_chains[len(top_chains)-1-k][1].ix, \n",
    "                     top_chains[len(top_chains)-1-k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "        plt.title(date, fontsize=16)\n",
    "        plt.xticks([]); plt.yticks([])\n",
    "        # make directory to save results to:\n",
    "        resultsfolder = processed_image_path+'results/'\n",
    "        if not os.path.exists(resultsfolder):\n",
    "            os.mkdir(resultsfolder)\n",
    "        plt.savefig(resultsfolder+image[:-4]+'_topchains.png',dpi=200)\n",
    "        plt.show()\n",
    "\n",
    "        return topchains_dfs\n",
    "    else:\n",
    "        print('No chains passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box 001 raster dimensions: (235, 221)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /media/jukes/jukes1/LS8aws/Box001/rotated_c2/img_yidx_Box001.csv does not exist: '/media/jukes/jukes1/LS8aws/Box001/rotated_c2/img_yidx_Box001.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0fdf42aa8fc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# read in image Greenland Polar Stereographic coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     PSy = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_yidx_Box'+BoxID+'.csv',\n\u001b[0;32m---> 23\u001b[0;31m                               delimiter=' ',header=None))\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m# read in image Greenland Polar Stereographic coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     PSx = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_xidx_Box'+BoxID+'.csv',\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /media/jukes/jukes1/LS8aws/Box001/rotated_c2/img_yidx_Box001.csv does not exist: '/media/jukes/jukes1/LS8aws/Box001/rotated_c2/img_yidx_Box001.csv'"
     ]
    }
   ],
   "source": [
    "for BoxID in BoxIDs:\n",
    "    t1 = time.time()\n",
    "    processed_image_path = basepath+'Box'+BoxID+'/'+rotated_foldername\n",
    "    imagelist = []\n",
    "    for file in os.listdir(processed_image_path):\n",
    "        if file.endswith('PS.pgm') and 'L1TP' in file: # L1TP corrected images only\n",
    "            imagelist.append(file)\n",
    "        elif file.endswith('cut.pgm'):\n",
    "            boxfile = file\n",
    "        \n",
    "    # Load terminus box\n",
    "    box = Image.open(processed_image_path+boxfile)\n",
    "    box_array = np.array(box)\n",
    "    if len(box_array.shape) == 3: # 3D array\n",
    "        box_array = box_array[:,:,0]/255 # grab 1D slice from array and convert to binary\n",
    "    elif len(box_array.shape) == 2: # 2D array\n",
    "        box_array = box_array # already in binary\n",
    "    print('Box',BoxID,'raster dimensions:', box_array.shape)\n",
    "    plt.imshow(box_array); plt.show()  # Display mask\n",
    "    \n",
    "    # read in image Greenland Polar Stereographic coordinates\n",
    "    PSy = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_yidx_Box'+BoxID+'.csv',\n",
    "                              delimiter=' ',header=None))\n",
    "    # read in image Greenland Polar Stereographic coordinates\n",
    "    PSx = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_xidx_Box'+BoxID+'.csv',\n",
    "                              delimiter=' ',header=None))\n",
    "    \n",
    "    # hold all top chains produced from terminus picking\n",
    "    topchains_alldfs = []\n",
    "    \n",
    "    # process all the images in parallel\n",
    "    pcount = 0\n",
    "    image_num = 1\n",
    "    nbatches = int(np.ceil(len(imagelist)/batch_size)) # round up to the next batch size\n",
    "    nfullbatches = int(np.floor(len(imagelist)/batch_size)) # number of full batches\n",
    "    print(nbatches, 'batches')\n",
    "    print(nfullbatches, 'full batches')\n",
    "    \n",
    "    # full batches\n",
    "    for b in range(0, nfullbatches):\n",
    "        pool = Pool() # initialize pool\n",
    "        batchimgs = imagelist[b*batch_size:(b+1)*batch_size]\n",
    "        topchains_dfs = pool.map(wtmm2d_img, batchimgs) # process all in pool\n",
    "        topchains_alldfs += topchains_dfs\n",
    "    \n",
    "    # for the last batch\n",
    "    if nbatches - nfullbatches == 1:\n",
    "        pool = Pool()\n",
    "        lastbatchimgs = imagelist[(b+1)*batch_size:] # grab all remaining images\n",
    "        topchains_dfs = pool.map(wtmm2d_img, lastbatchimgs) # process all in pool\n",
    "        topchains_alldfs += topchains_dfs\n",
    "\n",
    "    dfs = []\n",
    "    for df in topchains_alldfs:\n",
    "        if df == None:\n",
    "            topchains_alldfs.remove(df)\n",
    "        else:\n",
    "            dfs.append(df[0])\n",
    "    \n",
    "    print(str(time.time() - t1)+' sec to process '+str(len(imagelist))+' images.' )\n",
    "    # write terminus pick file\n",
    "    today = datetime.datetime.now().strftime(\"%Y_%m_%d\")  # today's date string\n",
    "    terminuspick_df = pd.concat(dfs) # concatenate all the top pick data together\n",
    "    terminuspick_df = terminuspick_df.reset_index(drop=True) # reset the index\n",
    "    terminuspick_df.to_csv(csvpath+'terminuspicks_Box'+BoxID.zfill(3)+'_'+today+'.csv') # write to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 3) Process 1 image at a time\n",
    "\n",
    "## 3A) Load terminus box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# use terminus box raster to mask out external chains\n",
    "# box = Image.open(basepath+'R_Box174_raster_cut.png')\n",
    "BOI = '012' # BoxID\n",
    "box = Image.open(basepath+'Box'+BOI+'/'+rotated_foldername+'R_Box'+BOI+'_raster_cut.png')\n",
    "######################################################################################\n",
    "if len(box_array.shape) == 3: # 3D array\n",
    "    box_array = box_array[:,:,0]/255 # grab 1D slice from array and convert to binary\n",
    "elif len(box_array.shape) == 2: # 2D array\n",
    "    box_array = box_array # already in binary\n",
    "print(box_array.shape)\n",
    "plt.imshow(box_array); plt.show()  # Display mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B) Open image(s) for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# # open glacier image for testing\n",
    "img = Image.open(basepath+'Box'+BOI+'/'+subfoldername+'R_LC08_L1TP_031005_20150716_20200908_02_T1_B8_Buffer012_PS.pgm')\n",
    "# img = Image.open(basepath+'R_LC08_L1TP_233017_20170813_20170814_01_RT_B8_Buffer174_PS.pgm')\n",
    "# OR generate circle image\n",
    "# img = generate_circle_image(100, 436, 428) # inputs are radius, xsize, ysize\n",
    "######################################################################################\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3C) Run wtmm2d and show outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# [dx,dy,F,f,gx,gy] = wtmm2d(img,'gauss',10)\n",
    "[dx,dy,mm,m,a] = wtmm2d_v2(img,'gauss',25) # scale = 10 pixels\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize outputs from wtmm2d:\n",
    "fig, axs = plt.subplots(2,3,figsize=(15,10))\n",
    "axs[0,0].imshow(dx, aspect='equal', cmap = 'gray', interpolation='none'); axs[0,0].set_title('dx') # x gradient\n",
    "axs[0,1].imshow(dy, aspect='equal', cmap = 'gray', interpolation='none'); axs[0,1].set_title('dy') # y gradient\n",
    "\n",
    "axs[0,2].imshow(a, aspect='equal', cmap = 'gray', interpolation='none'); axs[0,2].set_title('a') # argument            \n",
    "axs[1,0].imshow(mm, aspect='equal', cmap = 'gray', interpolation='none', vmin = np.min(mm), vmax = np.max(m)); \n",
    "axs[1,0].set_title('mm') # modulus maxima (interpolated)\n",
    "axs[1,1].imshow(m, aspect='equal', cmap = 'gray', interpolation='none',vmin = np.min(mm), vmax = np.max(m));\n",
    "axs[1,1].set_title('m') # modulus\n",
    "axs[-1, -1].axis('off')\n",
    "\n",
    "# Image.fromarray(mm).save('mm.tif')   \n",
    "# Image.fromarray(m).save('m.tif')   \n",
    "\n",
    "# plt.savefig('glacier_WTMM_test.png',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D) Mask using terminus box (emask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mask\n",
    "masked_a = emask(box_array, a)\n",
    "masked_mm = emask(box_array, mm)\n",
    "masked_m = emask(box_array, m)\n",
    "\n",
    "# Visualize masked outputs from wtmm2d:\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,10))\n",
    "\n",
    "axs[0].imshow(masked_a, aspect='equal', cmap = 'viridis', interpolation='none'); axs[0].set_title('a')              \n",
    "axs[1].imshow(masked_mm, aspect='equal', cmap = 'gray', interpolation='none', vmin = np.min(masked_mm), vmax = np.max(masked_mm)); \n",
    "axs[1].set_title('mm')\n",
    "axs[2].imshow(masked_m, aspect='equal', cmap = 'gray', interpolation='none',vmin = np.min(masked_m), vmax = np.max(masked_m));\n",
    "axs[2].set_title('m')\n",
    "# plt.savefig('glacier_WTMM_test.png',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3E) Chain remaining mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "cmm = wtmmchains(masked_mm,masked_a,1,10,3) # chain at a specified scale\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmm_passed = []\n",
    "# Filter chains based on size threshold\n",
    "for j in range(0, len(cmm)):\n",
    "    if cmm[j].size > 0: # adjust this condition to threshold\n",
    "        cmm_passed.append(cmm[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(masked_mm,cmap='gray')\n",
    "plt.xlim([0, mm.shape[1]])\n",
    "plt.ylim([0, mm.shape[0]])\n",
    "plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "    \n",
    "for k in range(0, len(cmm_passed)):\n",
    "    plt.plot(cmm_passed[k].ix, cmm_passed[k].iy, 's-', markersize=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3F) Use thresholds on chain properties to pick the glacier terminus chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "size_thresh = 0.4 # Size percentile across all images\n",
    "mod_thresh = 0.7 # Linemeanmod percentile across all images\n",
    "arg_thresh = 0.1 # left-right argument fraction\n",
    "metric = 0 # 0 = mass, 1 = scaledmass, 2 = size\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in Greenland Polar Stereographic coordinates\n",
    "PSy = np.array(pd.read_csv(basepath+'Box'+BOI+'/'+subfoldername+'img_idx_PSy_Box'+BOI+'.csv',\n",
    "                          delimiter=' ',header=None))\n",
    "# read in Greenland Polar Stereographic coordinates\n",
    "PSx = np.array(pd.read_csv(basepath+'Box'+BOI+'/'+subfoldername+'img_idx_PSx_Box'+BOI+'.csv',\n",
    "                          delimiter=' ',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_or_size = []\n",
    "passed_chains = []\n",
    "for chain in cmm_passed:\n",
    "    if chain.linemeanmod > mod_thresh: # only chains that pass the mod threshold\n",
    "        if chain.size > size_thresh: # only chains that pass the size threshold\n",
    "            [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "            if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "                if metric == 0:\n",
    "                    mass_or_size.append(chain.mass) # evaluate by mass (length*gradient value)\n",
    "                elif metric == 1:\n",
    "                    mass_or_size.append(chain.scaled_mass) # evaluate by scaled mass (mass/2**scale)\n",
    "                else:\n",
    "                    mass_or_size.append(chain.size)\n",
    "                PSxs = PSx[np.array(chain.ix,dtype=int)]\n",
    "                PSys = PSy[np.array(chain.iy,dtype=int)]\n",
    "                passed_chains.append(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_chains = pd.DataFrame(list(zip(mass_or_size, passed_chains)), columns=['metric_val','chainobj'])\n",
    "top_chains = top_chains.sort_values(by=['metric_val'],ascending=False) # sort chains with highest metric at top\n",
    "top_chains = top_chains[:5].reset_index(drop=True) # and grab the top 5\n",
    "top_chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize top chains:\n",
    "colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(np.array(img), aspect='equal', cmap = 'gray')\n",
    "plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "for k in range(0, len(top_chains)):\n",
    "    # plot chains, darker = better picks\n",
    "    plt.plot(top_chains[k][1].ix, top_chains[k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "#     break\n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_chains[k][1].ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoterm",
   "language": "python",
   "name": "autoterm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
